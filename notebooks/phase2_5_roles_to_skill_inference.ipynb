{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "gpuType": "T4"
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "source": [
        "**Phase 2.5**\n",
        "\n",
        "from the JSON files of phase 2 results, we get list of skills and roles\n",
        "and comparing between them wouldnt provide us with appropriate results hence, we move to this phase\n",
        "\n",
        "Phase 2.5 is responsible for seperating the skills from the roles that we have from phasse 2, so that the skill gap analysis in future stages can be meaningful and not misleading"
      ],
      "metadata": {
        "id": "L2LbGTt9ZknE"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "!git clone https://github.com/tanisha0804/Industry-Academia-alignment.git"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "A9etFWf8tXla",
        "outputId": "608cc839-bb17-47c7-d1e8-b0a4af742aea"
      },
      "execution_count": 19,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "fatal: destination path 'Industry-Academia-alignment' already exists and is not an empty directory.\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!pip install google-generativeai\n",
        "import json\n",
        "import re\n",
        "import time\n",
        "import os\n",
        "from pathlib import Path\n",
        "from collections import defaultdict\n",
        "import google.generativeai as genai"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "vE0QdhETtcCP",
        "outputId": "7d4156ba-8b5e-4ed1-d4d5-739d63f6a2f5"
      },
      "execution_count": 33,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Requirement already satisfied: google-generativeai in /usr/local/lib/python3.12/dist-packages (0.8.5)\n",
            "Requirement already satisfied: google-ai-generativelanguage==0.6.15 in /usr/local/lib/python3.12/dist-packages (from google-generativeai) (0.6.15)\n",
            "Requirement already satisfied: google-api-core in /usr/local/lib/python3.12/dist-packages (from google-generativeai) (2.28.1)\n",
            "Requirement already satisfied: google-api-python-client in /usr/local/lib/python3.12/dist-packages (from google-generativeai) (2.187.0)\n",
            "Requirement already satisfied: google-auth>=2.15.0 in /usr/local/lib/python3.12/dist-packages (from google-generativeai) (2.43.0)\n",
            "Requirement already satisfied: protobuf in /usr/local/lib/python3.12/dist-packages (from google-generativeai) (5.29.5)\n",
            "Requirement already satisfied: pydantic in /usr/local/lib/python3.12/dist-packages (from google-generativeai) (2.12.3)\n",
            "Requirement already satisfied: tqdm in /usr/local/lib/python3.12/dist-packages (from google-generativeai) (4.67.1)\n",
            "Requirement already satisfied: typing-extensions in /usr/local/lib/python3.12/dist-packages (from google-generativeai) (4.15.0)\n",
            "Requirement already satisfied: proto-plus<2.0.0dev,>=1.22.3 in /usr/local/lib/python3.12/dist-packages (from google-ai-generativelanguage==0.6.15->google-generativeai) (1.26.1)\n",
            "Requirement already satisfied: googleapis-common-protos<2.0.0,>=1.56.2 in /usr/local/lib/python3.12/dist-packages (from google-api-core->google-generativeai) (1.72.0)\n",
            "Requirement already satisfied: requests<3.0.0,>=2.18.0 in /usr/local/lib/python3.12/dist-packages (from google-api-core->google-generativeai) (2.32.4)\n",
            "Requirement already satisfied: cachetools<7.0,>=2.0.0 in /usr/local/lib/python3.12/dist-packages (from google-auth>=2.15.0->google-generativeai) (6.2.4)\n",
            "Requirement already satisfied: pyasn1-modules>=0.2.1 in /usr/local/lib/python3.12/dist-packages (from google-auth>=2.15.0->google-generativeai) (0.4.2)\n",
            "Requirement already satisfied: rsa<5,>=3.1.4 in /usr/local/lib/python3.12/dist-packages (from google-auth>=2.15.0->google-generativeai) (4.9.1)\n",
            "Requirement already satisfied: httplib2<1.0.0,>=0.19.0 in /usr/local/lib/python3.12/dist-packages (from google-api-python-client->google-generativeai) (0.31.0)\n",
            "Requirement already satisfied: google-auth-httplib2<1.0.0,>=0.2.0 in /usr/local/lib/python3.12/dist-packages (from google-api-python-client->google-generativeai) (0.2.1)\n",
            "Requirement already satisfied: uritemplate<5,>=3.0.1 in /usr/local/lib/python3.12/dist-packages (from google-api-python-client->google-generativeai) (4.2.0)\n",
            "Requirement already satisfied: annotated-types>=0.6.0 in /usr/local/lib/python3.12/dist-packages (from pydantic->google-generativeai) (0.7.0)\n",
            "Requirement already satisfied: pydantic-core==2.41.4 in /usr/local/lib/python3.12/dist-packages (from pydantic->google-generativeai) (2.41.4)\n",
            "Requirement already satisfied: typing-inspection>=0.4.2 in /usr/local/lib/python3.12/dist-packages (from pydantic->google-generativeai) (0.4.2)\n",
            "Requirement already satisfied: grpcio<2.0.0,>=1.33.2 in /usr/local/lib/python3.12/dist-packages (from google-api-core[grpc]!=2.0.*,!=2.1.*,!=2.10.*,!=2.2.*,!=2.3.*,!=2.4.*,!=2.5.*,!=2.6.*,!=2.7.*,!=2.8.*,!=2.9.*,<3.0.0dev,>=1.34.1->google-ai-generativelanguage==0.6.15->google-generativeai) (1.76.0)\n",
            "Requirement already satisfied: grpcio-status<2.0.0,>=1.33.2 in /usr/local/lib/python3.12/dist-packages (from google-api-core[grpc]!=2.0.*,!=2.1.*,!=2.10.*,!=2.2.*,!=2.3.*,!=2.4.*,!=2.5.*,!=2.6.*,!=2.7.*,!=2.8.*,!=2.9.*,<3.0.0dev,>=1.34.1->google-ai-generativelanguage==0.6.15->google-generativeai) (1.71.2)\n",
            "Requirement already satisfied: pyparsing<4,>=3.0.4 in /usr/local/lib/python3.12/dist-packages (from httplib2<1.0.0,>=0.19.0->google-api-python-client->google-generativeai) (3.2.5)\n",
            "Requirement already satisfied: pyasn1<0.7.0,>=0.6.1 in /usr/local/lib/python3.12/dist-packages (from pyasn1-modules>=0.2.1->google-auth>=2.15.0->google-generativeai) (0.6.1)\n",
            "Requirement already satisfied: charset_normalizer<4,>=2 in /usr/local/lib/python3.12/dist-packages (from requests<3.0.0,>=2.18.0->google-api-core->google-generativeai) (3.4.4)\n",
            "Requirement already satisfied: idna<4,>=2.5 in /usr/local/lib/python3.12/dist-packages (from requests<3.0.0,>=2.18.0->google-api-core->google-generativeai) (3.11)\n",
            "Requirement already satisfied: urllib3<3,>=1.21.1 in /usr/local/lib/python3.12/dist-packages (from requests<3.0.0,>=2.18.0->google-api-core->google-generativeai) (2.5.0)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.12/dist-packages (from requests<3.0.0,>=2.18.0->google-api-core->google-generativeai) (2025.11.12)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "os.environ[\"GEMINI_API_KEY\"] = \"AIzaSyAJv8kKH_T22TDUSnbcisZYJY36PxKZ2ZY\"\n",
        "\n",
        "genai.configure(api_key=os.getenv(\"GEMINI_API_KEY\"))\n"
      ],
      "metadata": {
        "id": "ICFkW9mytj9w"
      },
      "execution_count": 21,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "repo_root = Path(\".\")\n",
        "\n",
        "with open(repo_root / \"/content/Industry-Academia-alignment/outputs/processed_data/industry_skill_clusters.json\") as f:\n",
        "    industry_clusters = json.load(f)\n"
      ],
      "metadata": {
        "id": "lxcHw2kWtoA4"
      },
      "execution_count": 22,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# removing noise, numbers and the usual JD boilerplate\n",
        "\n",
        "NOISE_WORDS = [\n",
        "    \"job\", \"role\", \"description\", \"details\",\n",
        "    \"programme\", \"program\", \"skills\"\n",
        "]\n",
        "\n",
        "def clean_role(phrase):\n",
        "    phrase = phrase.lower()\n",
        "    phrase = re.sub(r\"\\b\\d+\\b\", \"\", phrase)  # remove numbers\n",
        "    for w in NOISE_WORDS:\n",
        "        phrase = phrase.replace(w, \"\")\n",
        "    phrase = re.sub(r\"\\s+\", \" \", phrase).strip()\n",
        "    return phrase"
      ],
      "metadata": {
        "id": "X5QZdZwKuln1"
      },
      "execution_count": 24,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# returns unique roles from the cluster\n",
        "def extract_distinct_roles(cluster_phrases):\n",
        "    cleaned = [clean_role(p) for p in cluster_phrases]\n",
        "    cleaned = [p for p in cleaned if len(p.split()) >= 2]\n",
        "    unique_roles = sorted(set(cleaned))\n",
        "\n",
        "    return unique_roles\n",
        "\n",
        "cluster_to_roles = {}\n",
        "\n",
        "for cid, phrases in industry_clusters.items():\n",
        "    roles = extract_distinct_roles(phrases)\n",
        "    cluster_to_roles[cid] = roles\n",
        "\n",
        "# Inspect the broad cluster (e.g., cluster 0)\n",
        "cluster_to_roles.get(\"0\", [])"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "HIDhrNlRuxc8",
        "outputId": "b87f1d80-e946-4a4a-cf59-2f656efb04c9"
      },
      "execution_count": 34,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "['ai analytics',\n",
              " 'ai consultant',\n",
              " 'ai consulting',\n",
              " 'analyst intern',\n",
              " 'automation intern',\n",
              " 'aveva software developer',\n",
              " 'developer intern',\n",
              " 'developer intern aveva',\n",
              " 'devops intern',\n",
              " 'digital intern',\n",
              " 'engineering intern',\n",
              " 'intern trainee',\n",
              " 'ios intern',\n",
              " 'software developer',\n",
              " 'software developer intern',\n",
              " 'software development',\n",
              " 'software engineer',\n",
              " 'software engineer intern',\n",
              " 'trainee software']"
            ]
          },
          "metadata": {},
          "execution_count": 34
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "model = genai.GenerativeModel(\"models/gemini-flash-latest\")\n",
        "\n",
        "def infer_skills_for_role(role):\n",
        "    prompt = f\"\"\"\n",
        "Given the job role: \"{role}\"\n",
        "\n",
        "List the 3 to 4 most important TECHNICAL skills required for this role.\n",
        "\n",
        "Rules:\n",
        "- Only technical skills\n",
        "- No soft skills\n",
        "- No job titles\n",
        "- 1–3 words per skill\n",
        "- Use industry-standard terminology\n",
        "\n",
        "Return ONLY a JSON array of strings.\n",
        "\"\"\"\n",
        "\n",
        "    response = model.generate_content(prompt)\n",
        "\n",
        "    # Gemini returns text, so parse JSON carefully\n",
        "    text = response.text.strip()\n",
        "\n",
        "    # Safety: extract JSON array only\n",
        "    start = text.find(\"[\")\n",
        "    end = text.rfind(\"]\") + 1\n",
        "\n",
        "    return json.loads(text[start:end])\n"
      ],
      "metadata": {
        "id": "CrqUSE_ntt8m"
      },
      "execution_count": 36,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# ---------- COLLECT ALL DISTINCT JOB ROLES ----------\n",
        "all_roles = sorted({\n",
        "    role\n",
        "    for roles in cluster_to_roles.values()\n",
        "    for role in roles\n",
        "})\n",
        "\n",
        "print(f\"Total distinct job roles: {len(all_roles)}\")\n",
        "print(all_roles)\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "pp6GQafnGCSo",
        "outputId": "e99ffc96-81fb-4094-beae-26d84f2f03e4"
      },
      "execution_count": 38,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Total distinct job roles: 22\n",
            "['ai analytics', 'ai consultant', 'ai consulting', 'analyst intern', 'automation intern', 'aveva software developer', 'developer intern', 'developer intern aveva', 'devops intern', 'digital intern', 'engineer intern cloudera', 'engineering intern', 'intern trainee', 'ios intern', 'sdet intern', 'software developer', 'software developer intern', 'software development', 'software engineer', 'software engineer intern', 'software engineer tejas', 'trainee software']\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# ---------- BUILD INDUSTRY SKILL UNIVERSE ----------\n",
        "industry_skill_universe = sorted({\n",
        "    skill\n",
        "    for skills in role_skill_map.values()\n",
        "    for skill in skills\n",
        "})\n",
        "\n",
        "repo_root = Path(\".\")\n",
        "output_dir = repo_root / \"outputs/processed_data\"\n",
        "output_dir.mkdir(parents=True, exist_ok=True)\n",
        "\n",
        "with open(output_dir / \"industry_role_to_skills.json\", \"w\") as f:\n",
        "    json.dump(role_skill_map, f, indent=2)\n",
        "\n",
        "with open(output_dir / \"industry_skill_universe.json\", \"w\") as f:\n",
        "    json.dump(industry_skill_universe, f, indent=2)\n",
        "\n",
        "print(\"✅ Phase 2.5 completed successfully using batch inference.\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Yjh6RSU0vEUU",
        "outputId": "52bf3309-4d32-4be8-94f7-6fdf920e3552"
      },
      "execution_count": 39,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "✅ Phase 2.5 completed successfully using batch inference.\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "#gives a list of models available and their generation methods to check which model would work\n",
        "import google.generativeai as genai\n",
        "\n",
        "for m in genai.list_models():\n",
        "    print(m.name, \"→\", m.supported_generation_methods)\n"
      ],
      "metadata": {
        "id": "pLtgjToNv8Qc"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}